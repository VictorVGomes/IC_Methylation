---
title: "Efeito do fumo na metilação do DNA em células CD8T"
author: "Victor Vinícius Gomes"
format: pdf
editor: visual
---

# Efeito do fumo na metilação do DNA em células CD8T do sangue humano

A instalação dos pacotes a serem utilizados é o primeiro passo para iniciar a análise de dados de metilação. Usando a função do pacote `BiocManager` , `install()` , instala-se os pacotes necessários, e listados nos códigos. Alguns têm tamanho mediano, e podem levar algum tempo até serem instalados.

#### Pacotes exigidos

```{r pacotes exigidos}
knitr::opts_chunk$set(echo = TRUE)
# pacotes usados e que não são do Bioconductor
pacotes = c("BiocManager",
            'devtools',
            "fs",
            'R.utils',
            'limma',
            'RColorBrewer',
            'factoextra',
            'umap',
            "IlluminaHumanMethylationEPICanno.ilm10b2.hg19",
            "IlluminaHumanMethylationEPICmanifest",
            'minfiData',
            'sva',
            'minfi',
            'GEOquery',
            'VennDetail',
            'IlluminaHumanMethylation450kanno.ilmn12.hg19',
            'missMethyl')

# O for loop a seguir instala os pacotes listados acima,
# e, se listados aqui, são usados diretamente no .rmd. 
# Caso exista exitância em instalar algum pacote aqui
# listado, é recomendado procurar um substituto que
# contenha as mesmas funcionalidades que o originalmente
# listado.

instalar_pacotes = function(pacotes){
  for(pacote in pacotes){
    if(!pacote %in% installed.packages())
      r = tryCatch(install.packages(pacote), error=function(e) e, warning=function(w) w)
    
      if(exists('r') & !(pacote %in% installed.packages()))
        rm(r)
        BiocManager::install(pacote)
    
    library(pacote, character.only = TRUE)
  }
}


instalar_pacotes(pacotes=pacotes)

# pacote dificil de instalar
devtools::install_github("markgene/maxprobes")

```

Após a instalação dos pacotes, pode-se iniciar a leitura dos dados.

`Como é uma parte que depende de como os dados foram coletados, cada experimento pode fazer essa parte de forma diferente, mas a ideia geral é a mesma, podendo-se generalizar boa parte dos passos aqui descritos, com pequenas alterações para comportar os diferentes experimentos possíveis.`

É possível observar a utilização da função **rm()** ao longo da análise. Vale denotar que o consumo de memória em processamento de dados genéticos é muito grande. Sendo assim, optou-se por remover as variáveis que já haviam sido usadas e não seriam mais acessadas.

#### Início da leitura dos dados

No caso dos dados sobre fumo, os arquivos .IDAT estão disponíveis em dois tipos: experimentos 450k e experimentos EPIC (850k). Como forma de usar ambos, foi decidido que os dados seriam lidos em experimentos separados e, depois, unificados em um único experimento 450k. Assim, a análise será baseada em um experimento 450k, mas é facilmente generalizável para um experimento EPIC.

No `minfi`, pacote usado para processar os dados, podemos listar os tipos de dados que formam uma análise:

1.  `rgSet`: formato que armazena as intensidades `red` e `green` da análise. Dependendo de como os dados foram lidos, também contém os dados dos fenótipos. É importante notar que as intensidades armazenadas aqui são apenas das cores `red` e `green`, sendo diferentes das intensidades relativas à metilação e não metilação, adquiridas posteriormente;

2.  `MSet`: `methylSet`, é o formato que armazena as intensidades de metilação (e de não metilação) de cada `probe`, para cada amostra. A forma mais simples de obter essa estrutura é usando a função `preprocessRaw()` no `rgSet` (importante notar que não é feita nenhuma normalização nos dados quando a função usada para chegar ao `Mset` é essa);

3.  Ao ponto em que tem-se o `MSet`, é possível criar duas novas estruturas: o `GMSet` e o `RSet`

3.1 O `GMSet`, ou `Genomic Methyl Set`, é quando o `MSet` é mapeado ao genoma usando a função `mapToGenome()`. Isso significa que cada probe do `MSet` terá sua coordenada genômica, além de algumas informações adicionais \[ref https://bioconductor.org/help/course-materials/2014/BioC2014/minfi_BioC2014.pdf pag. 8\].

3.2 Já o `RSet`, ou `Ratio Set`, refere-se ao `MSet` convertido em uma classe feita para armazenar os valores de Beta e/ou valores M, sendo assim, parte-se das intensidades metiladas e não metiladas e consegue-se os valores de beta e/ou M. É possível obter um `copy number`, a matriz com a soma das intensidades metiladas e não metiladas, para referência futura, dado que esse mapeamento é não-reversível.

4.  O `GRSet` - `Genomic Ratio Set` - é a próxima classe a ser gerada: é originada da fusão de 3.1 e 3.2, sendo apenas o `Ratio Set` mapeado ao genoma.

```{r funções auxiliares}

# algumas funções auxiliares

para_png = function(plotAsString, plotName, plotRes=TRUE,
                    dirToSave='/images', width=20, height=10, ...){
  # aceita argumentos keyWord da função png  (...)
  # plotRes só funciona bem em chunks do .rmd
  # cria diretório "/images/" se esse não existe
  dirr = paste0(getwd(), dirToSave)
  if(!isDirectory(dirr)) # se não existe, cria
    dir.create(dirr)  
  
  file_loc = paste0(dirr, '/', plotName, '.png')
  
  png(file_loc, res=90, width=width, height=height, ...)
  #
  eval(parse(text=plotAsString))
  #
  invisible(dev.off())
  if(plotRes) eval(parse(text=plotAsString))
  
  cat(paste('Salvo em:', file_loc))
}

# 
cria_dir_adiciona_arquivos = function(nomeDir, arquivos, print_results=FALSE){
  wd = paste0(getwd(), "/")
  caminho = paste0(wd, nomeDir)
  
  if(!dir.exists(caminho))
    dir.create(caminho)         # cria o diretório se esse não existe                      
  
  arquivos_ = unlist(strsplit(arquivos, split = "/", fixed = T))[seq(2, length(arquivos) * 2, 2)]
  
  arquivos = arquivos[which(!arquivos_ %in% list.files(caminho))]
  if(length(arquivos)!=0) file.copy(from = paste0(wd, arquivos), to = paste0(caminho,"/", arquivos_))
  
  if (print_results)
    print(list.files(caminho))
}

# Deszipador de arquivos
unzip_files = function(files){
  for(file in files){
    if(file.exists(file) & isGzipped(file) &
       !file.exists(sub(pattern = '.gz$', x = file, replacement = '')))
      gunzip(file, remove=T, )
  }
}
```



```{r organizacao de pastas e arquivos}
untar("GSE147430_RAW.tar", exdir = "GSE147430") # só deve ser feito uma vez

idatFiles = paste0('GSE147430/',list.files('GSE147430/', pattern = "idat.gz$"))
# nomes dos arquivos idat com a adição do caminho até eles do diretório atual

# 91% dos arquivos são 450k (121)
# os outros 9% são EPIC arrays (11)
# total de 132 pacientes (121+11)

files_450k = idatFiles[(file.size(idatFiles) < 5000000)] # file.size mede em bytes
files_EPIC = idatFiles[!(file.size(idatFiles) < 5000000)]


# Os arquivos serão lidos separadamente e, depois, unidos usando a função 
# combineArrays() do pacote minfi, e o produto final será um 450k set, pois
# como a maioria dos dados é 450k, teríamos muitos dados faltantes usando os
# 850k no geral.

# Para a leitura dos arquivos de forma separada, serão criados 2 diretórios:
# o diretório para 450k e o para EPIC arrays

dir_450k = "450kIdatFiles"
dir_EPIC = "EPICIdatFiles"
    
# Criando diretórios para 450k e EPIC
# não é necessário rodar  as funções mais que uma vez

cria_dir_adiciona_arquivos(nomeDir = dir_450k, arquivos = files_450k)
cria_dir_adiciona_arquivos(nomeDir = dir_EPIC, arquivos = files_EPIC)


# checando se o tamanho permanece o mesmo, mas em pastas separadas

tam_separado = (sum(file.size(paste0(dir_EPIC, "/", list.files(dir_EPIC, pattern='.idat.gz$'))))
                + sum(file.size(paste0(dir_450k, "/", list.files(dir_450k, pattern='.idat.gz$'))))) / 1e6

tam_original = sum(file.size(idatFiles)) / 1e6


print(tam_separado == tam_original)

# removendo arquivos do diretório original usados para criar
# os dois diretórios separados.
# unlink vai realmente deletar os arquivos passados a ele,
# portanto, cuidado ao usá-lo.

unlink(idatFiles)

# pronto para ler os arquivos 450k e EPIC em datasets separados

files_450k = list.files(dir_450k, recursive = T, full.names = T, pattern = ".gz")
files_EPIC = list.files(dir_EPIC, recursive = T, full.names = T, pattern = ".gz")

# deszipando arquivos IDAT, removendo arquivos zipados para desocupar espaço
unzip_files(files_450k); unlink(files_450k)
unzip_files(files_EPIC); unlink(files_EPIC)
```


```{r leitura e pre-processamento inicial dos dados}
# lendo experimentos 450k e EPIC separadamente

exp_450k = read.metharray.exp(dir_450k)
exp_EPIC = read.metharray.exp(dir_EPIC, force = T)

sampleNames(exp_450k) = sub('.*?_', '',sampleNames(exp_450k))
sampleNames(exp_EPIC) = sub('.*?_', '',sampleNames(exp_EPIC))

# geoMats e processamento delas

geoMat = getGEO('GSE147430', GSEMatrix = TRUE, getGPL = FALSE, parseCharacteristics = FALSE)
# a função getGEO deve ser rodada apenas como "getGEO('GSE147430')" na primeira vez, para poder criar o cache do
# arquivo usado nas próximas vezes
pd.450k = pData(geoMat$`GSE147430-GPL13534_series_matrix.txt.gz`)
pd.EPIC = pData(geoMat$`GSE147430-GPL21145_series_matrix.txt.gz`)
pd.450k$arrayDesign = '450K'
pd.EPIC$arrayDesign = 'EPIC'
rm(geoMat)


pd.All = rbind(pd.450k, pd.EPIC)

# reduzir uso de memória
rm(pd.450k, pd.EPIC)
pdCols = c('title', 'geo_accession', 'smoking_status:ch1', 'arrayDesign')

# algumas correções nos dados dos pacientes

pd.All = pd.All[pdCols]
pd.All$title = sub(']', '', sub('.*\\[','',pd.All$title))
colnames(pd.All)[3] = 'statusFumante'

row.names(pd.All) = pd.All$title


# combinando experimentos 450k e EPIC

rgSet_combined = combineArrays(exp_450k, exp_EPIC,
                               outType="IlluminaHumanMethylation450k")


# liberando memória

rm(exp_450k, exp_EPIC)

# checando se as amostras dos dados de fenótipos batem com 
# os dados do setRG

pd.All = pd.All[sampleNames(rgSet_combined),]

pd.All = as(pd.All, 'DataFrame')


# passando os dados de fenótipo para o rgSet

pData(rgSet_combined) = pd.All
rm(pd.All)
```

### Preprocessamento dos Dados

#### Controle de Qualidade

O controle de qualidade é parte essencial de qualquer análise onde muitas amostras são feitas, e é preciso controlar pelos problemas que podem ser causados pelo ambiente, erros humanos, etc. Ele confere toda a parte anterior à análise diferencial e que procura filtrar os dados de forma a remover *CpGs* com baixa qualidade, ou que não foram de fato detectados. Para esta comparação inicial de detecção, compara-se os *CpGs* de cada indivíduo com *probes* controle, que são compostos apenas de sinal de fundo, ou o ruído do ambiente. Se houver uma diferença significativa - de acordo com um p-valor a ser determinado - então dado *CpG* foi detectado. Quando este p-valor é grande, é um sinal de que aquele *CpG* é composto, em boa parte, por ruído de fundo, configurando um sinal ruim.

```{r detP}
detP = detectionP(rgSet_combined)
falharam <- detP > 0.01

para_png("barplot(colMeans(detP), xlab = 'Amostra', ylab = 'P-valores de detecção', names.arg = '', col=factor(pData(rgSet_combined)$statusFumante), las=2, cex.lab=1.5, cex.sub=1.5); abline(h=0.05, col='red');legend('topleft',legend=levels(factor(pData(rgSet_combined)$statusFumante)), fill=factor(pData(rgSet_combined)$statusFumante), bg='white')", 'Det-P-por-amostra', units = 'in')
```

```{r plotQC}
MSet_raw = preprocessRaw(rgSet_combined) # usado para controle de qualidade, também

# criando o methylSet, podemos fazer outro plot, que separa - ou agrupa - as
# amostras que têm baixa qualidade. Assim, é possível remover todas aquelas que
# não passarem no critério, feito por um limiar relativo ao log 2 da intensidade
# mediana metilada VS não metilada

qc = getQC(MSet_raw)



# é possível automatizar os plots de controle de qualidade usando a função
# qcReport() do Minfi, e analisar os resultados, que são retornados em um pdf
# no diretório atual

# qcReport(rgSet_combined, sampNames = sampleNames(rgSet_combined), sampGroups = pd.All$statusFumante)

para_png("plotQC(qc)", 'qc', units = 'cm')
```

```{r amostras ruins detP}
# remover p-valores maiores que um limiar. Neste caso, foi escolhido o valor
# 0.05. Assim, amostras que tiverem um p-valor maior que 0.05 serão automaticamente
# removidas. Foram detectadas 2 amostras ruins, mostradas a seguir. Essas serão
# removidas pelo nome, para evitar remover pelo índice da coluna, que pode mudar

amostra_ruim_det = colMeans(falharam) > 0.01
quais_amostras_detp = which(amostra_ruim_det==TRUE)
```

```{r density plot raw}
# usando o cutoff disponível na própria função plotQC, encontramos 
# as amostras que são consideradas ruins e as removemos de análises posteriores.
meds <- (qc$mMed + qc$uMed)/2
badSampleCutoff = 10.5 # do próprio minfi
whichBad <- which((meds < badSampleCutoff))

amostrasARemover = union.Vector(quais_amostras_detp, whichBad)
# serão removidas pelo método de preprocessamento, ou antes de preprocessar


# plot de densidade das amostras, raw

para_png("densityPlot(MSet_raw, sampGroups = pData(MSet_raw)$statusFumante, main='Sem Normalização')",'density-plot-raw', units = 'cm')
```

```{r density bean plot raw}
# outros plots estão disponíveis, como do densityBeanPlot:
para_png("densityBeanPlot(MSet_raw, sampGroups = pData(MSet_raw)$statusFumante)", 'density-bean-plot-raw', units = 'in')
```

```{r taxa media de falha por amostra}
# plot interessante para observar se há algum paciente com 
# problemas maiores de detecção dos probes

para_png("plot(as.factor(pData(rgSet_combined)$geo_accession), colMeans(falharam),
     main='Taxa média de falha por amostra', xlab='Amostra',
     ylab='taxa de probes com p-valor de detecção > 0.01', cex.sub=1.7, cex.lab=1.7, cex.main=2)", 'pvalor-falha-amostra', units = 'in')
```

```{r mdsPlot raw}
# índices a serem removidos antes da normalização  
probesRemover = rowMeans(falharam) > 0.05
probesRemover = which(probesRemover==TRUE)

# multi-dimensional scaling plot é uma forma de redução de dimensionalidade
# para a visualização dos dados
# será feito o mds antes e depois do preprocessamento, como forma de 
# analisar as diferenças e identificar padrões nas amostras
# o plot mds pode ser feito tanto no rg_set como nos dados processados
# como o preprocessamento é raw, não há necessidade de fazer o plot nos dados
# gerados por esse preprocessamento.

# analisar outras componentes pode revelar fontes de variação nos dados,
# no entanto, é melhor fazê-lo nos dados normalizados

para_png("mdsPlot(getM(MSet_raw),
        sampNames = rgSet_combined$geo_accession,
        sampGroups=rgSet_combined$statusFumante, )", 'mdsplot-raw', units = 'in')
```

```{r pca eixos 1 e 3 raw}
# O PCA parece ter funcionado bem com as componentes 1 e 4, podendo-se ver algum
# tipo de padrão. No entanto, é apenas um resultado preliminar, já que esses
# dados são enteriores à normalização aplicada, nos dados raw.
set.seed(42)
rgset_samp = t(getMeth(sample(MSet_raw, 4000)))

para_png("print(fviz_pca_ind(prcomp(rgset_samp, center = T, scale.=T), habillage = MSet_raw$statusFumante,
             axes = c(1, 3), addEllipses = T, ellipse.level=0.95))", 'pca-raw_comps1-3', units = 'in')
```

```{r rgset filtros iniciais}
# removendo amostras e probes problemáticos
rgSet_combinedFiltrado = rgSet_combined[-probesRemover, -amostrasARemover]
rm(rgSet_combined)
```

### Normalização

Serão testadas algumas formas diferentes de normalização. As duas candidatas serão a normalização quantílica e Noob. Será feita a demonstração da normalização com e sem as amostras ruins determinadas na parte de controle de qualidade, a fim de mostrar qual a diferença de ter-se apenas boas amostras nos dados analisados. Os plots feitos acima serão refeitos, levando em consideração a correção dos dados, para efeitos de comparação.


```{r De rgSet para MSet (normalizacao)}
rm(detP, falharam, MSet_raw, rgset_samp, qc)

# paleta de cores
pal <- brewer.pal(3,"Dark2")

# A normalização será a quantílica
MSetQuantile = preprocessQuantile(object = rgSet_combinedFiltrado,
                          fixOutliers = TRUE, 
                          removeBadSamples = TRUE,
                          badSampleCutoff = 10.5)


# Tentando o preprocessamento Noob, pois foi usada no paper que forneceu os dados
# deve-se remover as amostras ruins na mão

MSetNoob = preprocessNoob(rgSet_combined)
```

```{r mdsPlot quantile e noob, fig.width=20, fig.height=8}
para_png("par(mfrow=c(1,2));mdsPlot(getM(MSetQuantile), sampNames = MSetQuantile$geo_accession, sampGroups = MSetQuantile$statusFumante);mdsPlot(getM(MSetNoob), sampNames = MSetNoob$geo_accession, sampGroups = MSetNoob$statusFumante)",
 'Mset_quant_e_noob', units = 'in')
```

```{r densityPlot quantile}

para_png("densityPlot(getBeta(MSetQuantile), sampGroups = MSetQuantile$statusFumante, main='Normalização Quantílica')", 'Density-plot-quantilica', unit='cm')

```

```{r densityPlot Noob}
para_png("densityPlot(getBeta(MSetNoob), sampGroups = MSetNoob$statusFumante, main='Normalização Noob')", 'Density-plot-noob', unit='cm')

# nota-se que o preprocessamento Noob não foi bem ajustado aos dados, e portanto
# não será utilizado a partir deste ponto, sem a utilização dos demais plots
rm(MSetNoob)
```

Analisando os resultados obtidos nas normalizações determinadas, conclui-se que a normalização quantílica performou melhor. Assim, esta será usada nos passos posteriores, tal como a análise diferencial de metilação. Agora, certa atenção deve ser dada a outros tipos de `probes` que devem ser filtrados antes da análise diferencial. `Probes` relativos ao sexo dos indivíduos (cromossomos X e Y), `cross-hibridized probes` e `Single Nucleotide Polymorphism` (ou simplesmente `SNP`) devem ser removidos, no geral, como boa prática, quando não são do interesse geral da análise.

<!-- OS SEXOS FORAM PREDITOS NA NORMALIZAÇÃO, ENTÃO DA PRA FAZER ALGUNS PLOTS COM ISSO COMO SEPARADOR -->

```{r filtros adicionais pós-normalização}
ann450k = getAnnotation(IlluminaHumanMethylation450kanno.ilmn12.hg19)
cpgsManter = !(featureNames(MSetQuantile) %in% ann450k$Name[ann450k$chr %in% c("chrX","chrY")])
rm(ann450k)
# removendo CPGs relacionados ao sexo dos indivíduos.
# antes, nrow=450_292, agora nrow=439_769


MSetQuantile = MSetQuantile[cpgsManter, ]



# removendo SNP (single nucleotide polymorphism)
MSetQuantile <- dropLociWithSnps(MSetQuantile)

# nrow=423_718


# removendo CPGs cross-reativos ref: [https://www.tandfonline.com/doi/full/10.4161/epi.23470]
MSetQuantile <- maxprobes::dropXreactiveLoci(MSetQuantile)

# nrow=391_064
```

```{r mds pós filtragens}
para_png("mdsPlot(getM(MSetQuantile),
        sampNames = MSetQuantile$geo_accession,
        sampGroups=MSetQuantile$statusFumante, )", 'mdsplot-quantile-filtrado', units = 'in')

```

```{r mds usando design do array como separador}
para_png("mdsPlot(getM(MSetQuantile),
        sampNames = MSetQuantile$geo_accession,
        sampGroups=MSetQuantile$arrayDesign, )",
        'mdsplot-quantile-filtrado-arrayDesign',
        units = 'cm')
```

```{r pca pós filtragens}
set.seed(42)
mset_samp = t(assay(sample(MSetQuantile, 4000)))

para_png("print(fviz_pca_ind(prcomp(mset_samp, center = T, scale.=T), habillage = MSetQuantile$statusFumante, axes = c(1, 3), addEllipses = T, ellipse.level=0.95))",
         'pca-quantile_filtered_comps1-3',
         units = 'in')
```

```{r pca arrayDesign}
para_png("print(fviz_pca_ind(prcomp(mset_samp, center = T, scale.=T), habillage = MSetQuantile$arrayDesign, axes = c(1, 3), addEllipses = T, ellipse.level=0.95))",
         'pca-quantile_filtered_comps1-3-arrayDesign',
         units = 'in')
```

```{r umap array design}
MSetUmap = umap(mset_samp, preserve.seed = TRUE)
para_png("plot(MSetUmap$layout, col=factor(MSetQuantile$arrayDesign), pch=16, main='UMap Usando o Design do Array como Grupo', xlab='Dimensão 1', ylab='Dimensão 2')",
         'UMap-arrayDesign',
         units='px',
         width=900,
         height=500,
)
```

```{r umap status fumante}
para_png("plot(MSetUmap$layout, col=factor(MSetQuantile$statusFumante), pch=16, main='UMap Usando o Status de Fumo do Indivíduo como Grupo', xlab='Dimensão 1', ylab='Dimensão 2')",
         'UMap-statusFumante',
         units='in')

rm(MSetUmap)
```


Decidiu-se, por conta da perfeita separação entre os designs de array, que a análise seguirá apenas com os arrays do tipo "450K". A filtragem é feita a seguir:

```{r}
MSetQuantile = MSetQuantile[,MSetQuantile$arrayDesign=='450K']
```

```{r}
dim(MSetQuantile)
MSetQuantile$arrayDesign # sobrou apenas 450K
                         # removendo a coluna referente a esta variável, já que não tem mais importância
colData(MSetQuantile) = colData(MSetQuantile)[, -which(colnames(colData(MSetQuantile)) == 'arrayDesign')]
```


```{r}
MSetQuantile$predictedSex = ifelse(MSetQuantile$predictedSex=='F'|MSetQuantile$predictedSex==0, 0, 1)
design = model.matrix(~ MSetQuantile$statusFumante)
colnames(design) = c('Intercepto', 'fumante')
fit = lmFit(getM(MSetQuantile), design)
fit = eBayes(fit)
tt_fumante = topTable(fit, )
tt_fumante
updown_fumante = decideTests(fit)
summary(updown_fumante)
```



```{r}
design2 = model.matrix(~ MSetQuantile$statusFumante + MSetQuantile$predictedSex)
colnames(design2) = c('nao_fumante_mulher', 'fumante', 'sexo_masculino')
fit2 = lmFit(getM(MSetQuantile), design2)
fit2 = eBayes(fit2)
tt_full = topTable(fit2,)
tt_full
updown_full = decideTests(fit2)
summary(updown_full)
```



```{r}
a = venndetail(list(fumantes_fit1=rownames(updown_full[(updown_fumante[, 'fumante']==1), 1]), fumantes_fit2=rownames(updown_full[(updown_full[, 'fumante']==1), 1])))
plot(a)
```




```{r}
a = venndetail(list(fumantes_fit1=rownames(updown_full[(updown_fumante[, 'fumante']==-1), 1]), fumantes_fit2 = rownames(updown_full[(updown_full[, 'fumante']==-1), 1])))
plot(a)
```

Considerando que a mudança de CpGs metilados foi mínima, é justo dizer que o sexo ajuda a explicar a variância, mas não é útil na identificação de CpGs interessantes para análises posteriores.

# Gene Ontology

Testando algumas coisas sobre GO.

```{r}
cpgs_fumante = rownames(updown_fumante[updown_fumante[,"fumante"]!=0, ])
gst = gometh(sig.cpg=cpgs_fumante, all.cpg=rownames(MSetQuantile), collection="GO",
              plot.bias=TRUE)
```


```{r}
topGSA(gst, n=10)
```



## Outra forma de filtrar os arrays do  tipo EPIC é antes da normalização:

```{r filtrando para 450k antes de normalizar}
rgSet_combinedFiltrado_450k = rgSet_combinedFiltrado[, rgSet_combinedFiltrado$arrayDesign=='450K']
```


```{r normalização quantilica}
mset_quantile_450k = preprocessQuantile(
   object = rgSet_combinedFiltrado_450k,
   fixOutliers = TRUE, 
   removeBadSamples = TRUE,
   badSampleCutoff = 10.5
)
# nrow=450_292
```


```{r filtragens adicionais 450knorm}
ann450k = getAnnotation(IlluminaHumanMethylation450kanno.ilmn12.hg19)
cpgsManter = !(featureNames(mset_quantile_450k) %in% ann450k$Name[ann450k$chr %in% c("chrX","chrY")])
rm(ann450k)

mset_quantile_450k = mset_quantile_450k[cpgsManter, ]
# removendo CPGs relacionados ao sexo dos indivíduos.
# antes, nrow=450_292, agora nrow=439_769


# removendo SNP (single nucleotide polymorphism)
mset_quantile_450k <- dropLociWithSnps(mset_quantile_450k)
# nrow=423_718


# removendo CPGs cross-reativos ref: [https://www.tandfonline.com/doi/full/10.4161/epi.23470]
mset_quantile_450k <- maxprobes::dropXreactiveLoci(mset_quantile_450k)
# nrow=391_064
```


```{r mdsPlot quantile450k, fig.width=20, fig.height=8}
para_png(
 "mdsPlot(getM(mset_quantile_450k), sampNames = mset_quantile_450k$geo_accession, sampGroups = mset_quantile_450k$statusFumante)",
 'Mset_quant450k',
 units = 'in'
)
```

```{r densityPlot quantile}

para_png("densityPlot(getBeta(mset_quantile_450k), sampGroups = mset_quantile_450k$statusFumante, main='Normalização Quantílica')", 'Density-plot-quantilica450k', unit='cm')

```


```{r mdsPlot quantile450k by sex, fig.width=20, fig.height=8}
para_png(
 "mdsPlot(getM(mset_quantile_450k), sampNames = mset_quantile_450k$geo_accession, sampGroups = mset_quantile_450k$predictedSex)",
 'Mset_quant450k_bysex',
 units = 'in'
)
```





```{r 450k pca pós filtragens,}
set.seed(42)
mset_samp450k = t(assay(sample(mset_quantile_450k, 4000)))

para_png("print(fviz_pca_ind(prcomp(mset_samp450k, center = T, scale.=T), habillage = mset_quantile_450k$statusFumante, axes = c(1, 2), addEllipses = T, ellipse.level=0.95))",
         'pca-quantile_filtered_comps1-3-450k',
         units = 'px', width = 900, height=500)
```

```{r 450k pca arrayDesign}
para_png("print(fviz_pca_ind(prcomp(mset_samp450k, center = T, scale.=T), habillage = mset_quantile_450k$predictedSex, axes = c(1, 2), addEllipses = T, ellipse.level=0.95))",
         'pca-quantile_filtered_comps1-3-arrayDesign-450k',
         units = 'in')
```

```{r 450k umap array design}
MSetUmap450k = umap(mset_samp450k, preserve.seed = TRUE)
para_png("plot(MSetUmap450k$layout, col=factor(mset_quantile_450k$predictedSex), pch=16, main='UMap Usando o Sexo Predito como Grupo', xlab='Dimensão 1', ylab='Dimensão 2')",
         'UMap-sex-450k',
         units='px',
         width=900,
         height=500,
)
```

```{r 450k umap status fumante}
para_png("plot(MSetUmap450k$layout, col=factor(mset_quantile_450k$statusFumante), pch=16, main='UMap Agrupando por Status de Fumo', xlab='Dimensão 1', ylab='Dimensão 2')",
         'UMap-statusFumante-450k',
         units='in')

rm(MSetUmap450k)
```


### testes de hipótese 450k

```{r testes de hipótese 450k}
design450k = model.matrix(~ mset_quantile_450k$statusFumante)
colnames(design450k) = c('Intercepto', 'fumante')
fit450k = lmFit(getM(mset_quantile_450k), design)
fit450k = eBayes(fit450k)
tt_fumante450k = topTable(fit450k, )
tt_fumante450k
updown_fumante450k = decideTests(fit450k)
summary(updown_fumante450k)
```




```{r}
write.csv(topTable(fit450k, number = 100), file='resultados_cpgs.csv')
```



```{r}
session_info(to_file = TRUE)
```


