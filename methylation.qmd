---
title: "Efeito do fumo na metilação do DNA em células CD8T"
author: "Victor Vinícius Gomes"
format: pdf
editor: visual
---

# Efeito do fumo na metilação do DNA em células CD8T do sangue humano

A instalação dos pacotes a serem utilizados é o primeiro passo para iniciar a análise de dados de metilação. Usando a função do pacote `BiocManager` , `install()` , instala-se os pacotes necessários, e listados nos códigos. Alguns têm tamanho mediano, e podem levar algum tempo até serem instalados.

#### Pacotes exigidos

```{r}
knitr::opts_chunk$set(echo = TRUE)
# pacotes usados e que não são do Bioconductor
pacotes = c("fs", 'R.utils', 'limma', 'RColorBrewer', 'devtools')

for(pacote in pacotes){
  if(!pacote %in% installed.packages())
    install.packages(pacote)
  library(pacote, character.only = TRUE)}


library(minfi)
library(GEOquery)
# library(GEOquery)
# library(IlluminaHumanMethylation450kmanifest)
# library(IlluminaHumanMethylation450kanno.ilmn12.hg19)
# BiocManager::install("IlluminaHumanMethylationEPICanno.ilm10b2.hg19")
# BiocManager::install("IlluminaHumanMethylationEPICmanifest")
# BiocManager::install('minfiData')
# devtools::install_github("markgene/maxprobes")
```

Após a instalação dos pacotes, pode-se iniciar a leitura dos dados.

`Como é uma parte que depende de como os dados foram coletados, cada experimento pode fazer essa parte de forma diferente, mas a ideia geral é a mesma, podendo-se generalizar boa parte dos passos aqui descritos, com pequenas alterações para comportar os diferentes experimentos possíveis.`

É possível observar a utilização da função **rm()** ao longo da análise. Vale denotar que o consumo de memória em processamento de dados genéticos é muito grande. Sendo assim, optou-se por remover as variáveis que já haviam sido usadas e não seriam mais acessadas.

#### Início da leitura dos dados

No caso dos dados sobre fumo, os arquivos .IDAT estão disponíveis em dois tipos: experimentos 450k e experimentos EPIC (850k). Como forma de usar ambos

```{r}

# untar("GSE147430_RAW.tar", exdir = "GSE147430") # só deve ser feito uma vez

idatFiles = paste0('GSE147430/',list.files('GSE147430/', pattern = "idat"))
# nomes dos arquivos idat com a adição do caminho até eles do diretório atual

# 91% dos arquivos são 450k (121)
# os outros 9% são EPIC arrays (11)
# total de 132 pacientes (121+11)

files_450k = idatFiles[(file.size(idatFiles) < 5000000)] # file.size mede em bytes
files_EPIC = idatFiles[!(file.size(idatFiles) < 5000000)]


# Os arquivos serão lidos separadamente e, depois, unidos usando a função 
# combineArrays() do pacote minfi, e o produto final será um 450k set, pois
# como a maioria dos dados é 450k, teríamos muitos dados faltantes usando os
# 850k no geral.

# Para a leitura dos arquivos de forma separada, serão criados 2 diretórios:
# o diretório para 450k e o para EPIC arrays

dir_450k = "450kIdatFiles"
dir_EPIC = "EPICIdatFiles"


cria_dir_adiciona_arquivos = function(nomeDir, arquivos, print_results=FALSE){
  wd = paste0(getwd(), "/")
  caminho = paste0(wd, nomeDir)
  
  if(!dir.exists(caminho))
    dir.create(caminho)         # cria o diretório se esse não existe                      
  
  arquivos_ = unlist(strsplit(arquivos, split = "/", fixed = T))[seq(2, length(arquivos) * 2, 2)]
  
  arquivos = arquivos[which(!arquivos_ %in% list.files(caminho))]
  if(length(arquivos)!=0) file.copy(from = paste0(wd, arquivos), to = paste0(caminho,"/", arquivos_))
  
  if (print_results)
    print(list.files(caminho))
}

    
# Criando diretórios para 450k e EPIC
# não é necessário rodar  as funções mais que uma vez

cria_dir_adiciona_arquivos(nomeDir = dir_450k, arquivos = files_450k)
cria_dir_adiciona_arquivos(nomeDir = dir_EPIC, arquivos = files_EPIC)


# checando se o tamanho permanece o mesmo, mas em pastas separadas

tam_separado = (sum(file.size(paste0(dir_EPIC, "/",list.files(dir_EPIC))))
                + sum(file.size(paste0(dir_450k, "/",list.files(dir_450k))))) / 1e6

tam_original = sum(file.size(idatFiles)) / 1e6


print(tam_separado == tam_original)

# removendo arquivos do diretório original usados para criar
# os dois diretórios separados

unlink(idatFiles)

# pronto para ler os arquivos 450k e EPIC em datasets separados

files_450k = list.files(dir_450k, recursive = T, full.names = T, pattern = ".gz")
files_EPIC = list.files(dir_EPIC, recursive = T, full.names = T, pattern = ".gz")


# deszipando arquivos IDAT
for(file in files_450k){
  if(file.exists(file) & isGzipped(file))
    gunzip(file, remove=T, skip=T)
}

for(file in files_EPIC){
  if(file.exists(file) & isGzipped(file))
    gunzip(file, remove=T, skip=T)
}


# lendo experimentos 450k e EPIC separadamente

exp_450k = read.metharray.exp(dir_450k)
exp_EPIC = read.metharray.exp(dir_EPIC, force = T)

sampleNames(exp_450k) = sub('.*?_', '',sampleNames(exp_450k))
sampleNames(exp_EPIC) = sub('.*?_', '',sampleNames(exp_EPIC))

# geoMats e processamento delas

geoMat = getGEO('GSE147430')
pd.450k = pData(geoMat$`GSE147430-GPL13534_series_matrix.txt.gz`)
pd.EPIC = pData(geoMat$`GSE147430-GPL21145_series_matrix.txt.gz`)
rm(geoMat)


pd.All = rbind(pd.450k, pd.EPIC)

# reduzir uso de memória
rm(pd.450k, pd.EPIC)
pdCols = c('title', 'geo_accession', 'smoking_status:ch1')

# algumas correções nos dados dos pacientes

pd.All = pd.All[pdCols]
pd.All$title = sub(']', '', sub('.*\\[','',pd.All$title))
colnames(pd.All)[3] = 'statusFumante'

row.names(pd.All) = pd.All$title


# combinando experimentos 450k e EPIC
rgSet_combined = combineArrays(exp_450k, exp_EPIC,
                               outType="IlluminaHumanMethylation450k")


# liberando memória
rm(exp_450k, exp_EPIC)

# checando se as amostras dos dados de fenótipos batem com 
# os dados do setRG

pd.All = pd.All[sampleNames(rgSet_combined),]

pd.All = as(pd.All, 'DataFrame')


# passando os dados de fenótipo para o rgSet
pData(rgSet_combined) = pd.All
rm(pd.All)
```


### Preprocessamento dos Dados

#### Controle de Qualidade

O controle de qualidade é parte essencial de qualquer análise onde muitas amostras são feitas, e é preciso controlar pelos problemas que podem ser causados pelo ambiente, erros humanos, etc. Ele confere toda a parte anterior à análise diferencial e que procura filtrar os dados de forma a remover *CpGs* com baixa qualidade, ou que não foram de fato detectados. Para esta comparação inicial de detecção, compara-se os *CpGs* de cada indivíduo com *probes* controle, que são compostos apenas de sinal de fundo, ou o ruído do ambiente. Se houver uma diferença significativa - de acordo com um p-valor a ser determinado - então dado *CpG* foi detectado. Quando este p-valor é grande, este é um sinal de que aquele *CpG* é composto, em boa parte, por ruído de fundo, configurando um sinal ruim.


```{r}
detP = detectionP(rgSet_combined)

barplot(colMeans(detP), xlab = 'Amostra',
        ylab = 'P-valores de detecção',
        names.arg = '',
        col=factor(pData(rgSet_combined)$statusFumante),
        las=2); abline(h=0.05, col='red');legend('topleft',legend=levels(factor(pData(rgSet_combined)$statusFumante)), fill=factor(pData(rgSet_combined)$statusFumante), bg='white')

```


```{r}
# remover p-valores maiores que um limiar. Neste caso, foi escolhido o valor
# 0.05. Assim, amostras que tiverem um p-valor maior que 0.05 serão automaticamente
# removidas. Não houve amostra ruim detectada neste passo, sendo assim,
# a linha abaixo será mantida, apenas para demonstrar como seria feita a remoção
# caso contrário.

rgSet_combined = rgSet_combined[, colMeans(detP)<0.05] 



# qcReport(rgSet_combined, sampNames = sampleNames(rgSet_combined), sampGroups = pd.All$statusFumante)


MSet_raw = preprocessRaw(rgSet_combined) # usado para controle de qualidade, também

# é possível automatizar os plots de controle de qualidade usando a função
# qcReport() do Minfi, e analisar os resultados, que são retornados em um pdf
# no diretório atual


# criando o methylSet, podemos fazer outro plot, que separa - ou agrupa - as
# amostras que têm baixa qualidade. Assim, é possível remover todas aquelas que
# não passarem no critério, feito por um limiar relativo ao log 2 da intensidade
# mediana metilada VS não metilada

qc = getQC(MSet_raw)

# usando o cutoff disponível na própria função plotQC, encontramos 
# as amostras que são consideradas ruins e as removemos de análises posteriores.
plotQC(qc)
```


```{r}
meds <- (qc$mMed + qc$uMed)/2
badSampleCutoff = 10.5 # do próprio minfi
whichBad <- which((meds < badSampleCutoff))
# serão removidas pelo método de preprocessamento


# plot de densidade das amostras, raw

densityPlot(MSet_raw, sampGroups = pData(MSet_raw)$statusFumante)
```


```{r}
# outros plots estão disponíveis, como do densityBeanPlot:
densityBeanPlot(MSet_raw, sampGroups = pData(MSet_raw)$statusFumante)
```



```{r}
# plot interessante para observar se há algum paciente com 
# problemas maiores de detecção dos probes

falharam <- detP > 0.05
plot(as.factor(pData(rgSet_combined)$geo_accession), colMeans(falharam),
     main='Taxa média de falha por amostra', xlab='Amostra',
     ylab='taxa de probes com p-valor de detecção > 0.05')
```



```{r}
# índices a serem removidos antes da normalização  
amostrasManter = colMeans(falharam)<0.05
probesManter = rowMeans(falharam)<0.05
dim(rgSet_combined)
rgSet_combined = rgSet_combined[probesManter, amostrasManter]

boxplot(detP)

# multi-dimensional scaling plot é uma forma de redução de dimensionalidade
# para a visualização dos dados
# será feito o mds antes e depois do preprocessamento, como forma de 
# analisar as diferenças e identificar padrões nas amostras
# o plot mds pode ser feito tanto no rg_set como nos dados processados
# como o preprocessamento é raw, não há necessidade de fazer o plot nos dados
# gerados por esse preprocessamento.
```



```{r}
# analisar outras componentes pode revelar fontes de variação nos dados,
# no entanto, é melhor fazê-lo nos dados normalizados
mdsPlot(rgSet_combined, sampNames = rgSet_combined$geo_accession, sampGroups=rgSet_combined$statusFumante)

```


```{r}
# Tentando pca

pca_rgset = princomp(as.matrix(rgSet_combined))

```


### Normalização

Serão testadas algumas formas diferentes de normalização. As duas candidatas serão a normalização quantílica e Noob. Será feita a demonstração da normalização com e sem as amostras ruins determinadas na parte de controle de qualidade, a fim de mostrar qual a diferença de ter-se apenas boas amostras nos dados analisados. Os plots feitos acima serão refeitos, levando em consideração a correção dos dados, para efeitos de comparação.

<!-- **DROP DE PROBES QUE NÃO FOI FEITO POR CONTROLE DE QUALIDADE PODE SER FEITO DEPOIS DA NORMALIZAÇÃO -->
<!-- DADO QUE NÃO HÁ PROBLEMA DE VALOR NO PROBE, E SIM EFEITO ESPECÍFICO DELE QUE QUER-SE EVITAR* -->
<!-- PARA DROPAR PROBES CROSS-REATIVOS::: -->
<!-- MsetEx_noXloci <- maxprobes::dropXreactiveLoci(MsetEx) -->
<!-- MsetEx_noXloci -->
<!-- Depending on the nature of your samples and your biological question you may also choose to filter out the probes from the X and Y chromosomes or probes that are known to have common SNPs at the CpG site. As the samples in this dataset were all derived from male donors, we will not be removing the sex chromosome probes as part of this analysis, however example code is provided below. A different dataset, which contains both male and female samples, is used to demonstrate a Differential Variability analysis and provides an example of when sex chromosome removal is necessary (Figure 13). -->

<!-- # if your data includes males and females, remove probes on the sex chromosomes -->
<!-- keep <- !(featureNames(mSetSqFlt) %in% ann450k$Name[ann450k$chr %in%  -->
<!--                                                         c("chrX","chrY")]) -->
<!-- table(keep) -->
<!-- mSetSqFlt <- mSetSqFlt[keep,] -->
<!-- There is a function in minfi that provides a simple interface for the removal of probes where common SNPs may affect the CpG. You can either remove all probes affected by SNPs (default), or only those with minor allele frequencies greater than a specified value. -->

<!-- # remove probes with SNPs at CpG site -->
<!-- mSetSqFlt <- dropLociWithSnps(mSetSqFlt) -->
<!-- mSetSqFlt -->


```{r}
# paleta de cores
pal <- brewer.pal(3,"Dark2")

MSet1 = preprocessQuantile(object = rgSet_combined,
                          fixOutliers = TRUE)

MSet = preprocessQuantile(object = rgSet_combined,
                          fixOutliers = TRUE, 
                          removeBadSamples = TRUE,
                          badSampleCutoff = 10.5)

MSet_noob = preprocessNoob(rgSet_combined)


dim(MSet); dim(MSet1)
par(mfrow=c(1,2));mdsPlot(getM(MSet1), sampNames = MSet1$geo_accession, sampGroups = MSet1$statusFumante);mdsPlot(getM(MSet), sampNames = MSet$geo_accession, sampGroups = MSet$statusFumante);mds



plotMDS(getM(MSet), sampNames = MSet$geo_accession,
        sampGroups = MSet$statusFumante, dim=c(1, 3))


plotMDS(getM(MSet), top=1000, gene.selection="common", 
        col=pal[factor(MSet$statusFumante)], dim=c(1,2));legend("topright", legend=levels(factor(MSet$statusFumante)), text.col=pal,
       cex=0.7, bg="white")



par(mfrow=c(1,3));densityPlot(rgSet_combined, sampGroups = rgSet_combined$statusFumante, main='Sem Normalização');densityPlot(getBeta(MSet), sampGroups = MSet$statusFumante, main='Normalização Quantílica');densityPlot(getBeta(MSet_noob), sampGroups = MSet_noob$statusFumante, main='Normalização Noob')

# nota-se que o preprocessamento Noob não foi bem ajustado aos dados, e portanto
# não será utilizado a partir deste ponto, sem a utilização dos demais plots
rm(MSet_noob)


```
